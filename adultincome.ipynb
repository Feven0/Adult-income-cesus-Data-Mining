{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import OneHotEncoder,LabelEncoder,StandardScaler \n# read in all our data\nadult_income = pd.read_csv(\"/kaggle/input/adult-census-income/adult.csv\")\n\nadult_income","metadata":{"execution":{"iopub.status.busy":"2023-06-10T11:46:19.601643Z","iopub.execute_input":"2023-06-10T11:46:19.602019Z","iopub.status.idle":"2023-06-10T11:46:19.697891Z","shell.execute_reply.started":"2023-06-10T11:46:19.601992Z","shell.execute_reply":"2023-06-10T11:46:19.69679Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#droping fnlwgt because it indicates number of people that a given observation represents\nadult_income.drop('fnlwgt', axis=1, inplace=True)\n\n# dropping education because it represents highest education which can be derived from education.num\nadult_income.drop('education.num', axis=1, inplace=True)  \nadult_income.drop('native.country', axis=1, inplace=True) \n\n# initial number of rows\nadult_income.shape[0]","metadata":{"execution":{"iopub.status.busy":"2023-06-10T11:46:19.699721Z","iopub.execute_input":"2023-06-10T11:46:19.700061Z","iopub.status.idle":"2023-06-10T11:46:19.726716Z","shell.execute_reply.started":"2023-06-10T11:46:19.700032Z","shell.execute_reply":"2023-06-10T11:46:19.725661Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"adult_income.isin(['?']).sum()","metadata":{"execution":{"iopub.status.busy":"2023-06-10T11:46:19.729024Z","iopub.execute_input":"2023-06-10T11:46:19.729479Z","iopub.status.idle":"2023-06-10T11:46:19.764407Z","shell.execute_reply.started":"2023-06-10T11:46:19.729442Z","shell.execute_reply":"2023-06-10T11:46:19.763445Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#drop rows with atleast one column value of ?\nadult_income.replace('?', np.nan, inplace=True)\nadult_income.dropna(inplace=True)\nadult_income.drop_duplicates(inplace=True)\n\n#new number of rows\nadult_income.shape[0]\n\nxx=adult_income","metadata":{"execution":{"iopub.status.busy":"2023-06-10T11:46:19.766622Z","iopub.execute_input":"2023-06-10T11:46:19.766935Z","iopub.status.idle":"2023-06-10T11:46:19.851312Z","shell.execute_reply.started":"2023-06-10T11:46:19.76691Z","shell.execute_reply":"2023-06-10T11:46:19.850344Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Encode categorical variables\ncategorical_cols = ['workclass', 'marital.status', 'occupation', 'relationship', 'race','sex']\n\nadult_income = pd.get_dummies(adult_income, columns=categorical_cols)\n\nle = LabelEncoder()\nadult_income['education'] = le.fit_transform(adult_income['education'])","metadata":{"execution":{"iopub.status.busy":"2023-06-10T11:46:19.852566Z","iopub.execute_input":"2023-06-10T11:46:19.853563Z","iopub.status.idle":"2023-06-10T11:46:19.893863Z","shell.execute_reply.started":"2023-06-10T11:46:19.853533Z","shell.execute_reply":"2023-06-10T11:46:19.893021Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"adult_income['income'] = adult_income['income'].map({'<=50K':0, '>50K':1})\nadult_income.income.head()","metadata":{"execution":{"iopub.status.busy":"2023-06-10T11:46:19.89491Z","iopub.execute_input":"2023-06-10T11:46:19.895932Z","iopub.status.idle":"2023-06-10T11:46:19.90831Z","shell.execute_reply.started":"2023-06-10T11:46:19.895899Z","shell.execute_reply":"2023-06-10T11:46:19.90698Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# #normalize input data,ensure that each feature contributes equally to the analysis\n# numerical_cols = ['age','capital.gain','capital.loss','hours.per.week']\n\n# scaler = StandardScaler()\n\n# adult_income[numerical_cols] = scaler.fit_transform(adult_income[numerical_cols])\n# adult_income.head()","metadata":{"execution":{"iopub.status.busy":"2023-06-10T11:46:19.909978Z","iopub.execute_input":"2023-06-10T11:46:19.910641Z","iopub.status.idle":"2023-06-10T11:46:19.919037Z","shell.execute_reply.started":"2023-06-10T11:46:19.910571Z","shell.execute_reply":"2023-06-10T11:46:19.917963Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#discretize age\nage_bins = [0,15,18,25, 35, 45, 55, 65, np.inf]\nage_labels = ['0-15','15-18','18-25' ,'25-35', '35-45', '45-55', '55-65', '65+']\nxx['age_bins'] = pd.cut(xx['age'], bins=age_bins, labels=age_labels) \n\n# Drop the original columns\nxx = xx.drop(['age'], axis=1)\n \n\n#discretize capitalloss\nloss_bins = [0,5, 1500, 1902, 2001, 2500, np.inf]\nloss_labels = ['0-5l','5-1500l','1500-1902l' ,'1902-2001l', '2001-2500l', '2500+ll']\nxx['capitalloss_bins'] = pd.cut(xx['capital.loss'], bins=loss_bins, labels=loss_labels, include_lowest=True) \n\n# Drop the original columns\nxx = xx.drop(['capital.loss'], axis=1)\n\n\n#discretize capital gain\n\n\ngain_bins = [0, 5, 20000, np.inf]\ngain_labels = ['0-5g', '5-20000g', '20000+g']\nxx['capitalgain_bins'] = pd.cut(xx['capital.gain'], bins=gain_bins, labels=gain_labels, include_lowest=True) \n\n# Drop the original columns\nxx = xx.drop(['capital.gain'], axis=1)\n\nxx\n\n \n\n#discretize capital gain\n\n\ngain_bins = [0, 35, 40, 168]\ngain_labels = ['part-time', 'full-time', 'over-time']\nxx['hoursperweek_bins'] = pd.cut(xx['hours.per.week'], bins=gain_bins, labels=gain_labels, include_lowest=True) \n\n# Drop the original columns\nxx = xx.drop(['hours.per.week'], axis=1)\n\nxx","metadata":{"execution":{"iopub.status.busy":"2023-06-10T11:46:19.920624Z","iopub.execute_input":"2023-06-10T11:46:19.920986Z","iopub.status.idle":"2023-06-10T11:46:19.974873Z","shell.execute_reply.started":"2023-06-10T11:46:19.920957Z","shell.execute_reply":"2023-06-10T11:46:19.973826Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# categorical_cols = ['hoursperweek_bins','capitalgain_bins','age_bins','capitalloss_bins']\n\n# adult_income = pd.get_dummies(adult_income, columns=categorical_cols)\n ","metadata":{"execution":{"iopub.status.busy":"2023-06-10T11:46:19.976474Z","iopub.execute_input":"2023-06-10T11:46:19.976835Z","iopub.status.idle":"2023-06-10T11:46:19.981963Z","shell.execute_reply.started":"2023-06-10T11:46:19.976807Z","shell.execute_reply":"2023-06-10T11:46:19.980489Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# income_50k = adult_income[adult_income['income'] == '>50K']\n# income_l50k = adult_income[adult_income['income'] == '<=50K']\n\n# # Extract capital gains for each income category\n# capital_gain_50k = income_50k['capital.gain']\n# capital_gain_l50k = income_l50k['capital.gain']\n\n# fig, axs = plt.subplots(2, 1)\n\n# axs[0].hist(capital_gain_50k, edgecolor='black')\n# axs[0].set_title('Distribution of Age for Income > 50K')\n\n# axs[1].hist(capital_gain_l50k, edgecolor='black')\n# axs[1].set_title('Distribution of Age for Income <= 50K')\n# plt.tight_layout()","metadata":{"execution":{"iopub.status.busy":"2023-06-10T11:46:19.985329Z","iopub.execute_input":"2023-06-10T11:46:19.986197Z","iopub.status.idle":"2023-06-10T11:46:19.998092Z","shell.execute_reply.started":"2023-06-10T11:46:19.986162Z","shell.execute_reply":"2023-06-10T11:46:19.996898Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"adult_income.to_csv('preadult.csv', sep=',')","metadata":{"execution":{"iopub.status.busy":"2023-06-10T11:46:20.305498Z","iopub.execute_input":"2023-06-10T11:46:20.30613Z","iopub.status.idle":"2023-06-10T11:46:20.551558Z","shell.execute_reply.started":"2023-06-10T11:46:20.306095Z","shell.execute_reply":"2023-06-10T11:46:20.550779Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import mean_absolute_error,accuracy_score,precision_score, recall_score, f1_score\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.datasets import make_regression\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import KFold","metadata":{"execution":{"iopub.status.busy":"2023-06-10T11:46:20.552913Z","iopub.execute_input":"2023-06-10T11:46:20.553696Z","iopub.status.idle":"2023-06-10T11:46:20.560058Z","shell.execute_reply.started":"2023-06-10T11:46:20.553665Z","shell.execute_reply":"2023-06-10T11:46:20.559101Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"opp=adult_income\ncc=adult_income\ndd=adult_income","metadata":{"execution":{"iopub.status.busy":"2023-06-10T11:46:20.561594Z","iopub.execute_input":"2023-06-10T11:46:20.562012Z","iopub.status.idle":"2023-06-10T11:46:20.573576Z","shell.execute_reply.started":"2023-06-10T11:46:20.561975Z","shell.execute_reply":"2023-06-10T11:46:20.572414Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = opp.drop('income', axis=1)\n# X = X.drop('capital.gain', axis=1)\n# X = X.drop('native.country', axis=1) \ny = opp.income","metadata":{"execution":{"iopub.status.busy":"2023-06-10T11:46:20.576025Z","iopub.execute_input":"2023-06-10T11:46:20.576398Z","iopub.status.idle":"2023-06-10T11:46:20.587264Z","shell.execute_reply.started":"2023-06-10T11:46:20.576309Z","shell.execute_reply":"2023-06-10T11:46:20.586086Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create target object and call it y\n\n# Create X\n# features = ['age', 'workclass', 'fnlwgt', 'education', 'education.num',\n#        'marital.status', 'occupation', 'relationship', 'race', 'sex',\n#        'capital.gain', 'capital.loss', 'hours.per.week', 'native.country']\nX = adult_income.drop('income', axis=1)\ny = adult_income.income","metadata":{"execution":{"iopub.status.busy":"2023-06-10T11:46:20.589575Z","iopub.execute_input":"2023-06-10T11:46:20.590094Z","iopub.status.idle":"2023-06-10T11:46:20.604581Z","shell.execute_reply.started":"2023-06-10T11:46:20.590055Z","shell.execute_reply":"2023-06-10T11:46:20.603288Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# adult_income[ 'capital.gain'].hist()","metadata":{"execution":{"iopub.status.busy":"2023-06-10T11:46:20.606226Z","iopub.execute_input":"2023-06-10T11:46:20.606578Z","iopub.status.idle":"2023-06-10T11:46:20.615431Z","shell.execute_reply.started":"2023-06-10T11:46:20.606548Z","shell.execute_reply":"2023-06-10T11:46:20.614255Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Split into validation and training data\ntrain_X, val_X, train_y, val_y = train_test_split(X, y, random_state=1)","metadata":{"execution":{"iopub.status.busy":"2023-06-10T11:46:20.688674Z","iopub.execute_input":"2023-06-10T11:46:20.689022Z","iopub.status.idle":"2023-06-10T11:46:20.708408Z","shell.execute_reply.started":"2023-06-10T11:46:20.688996Z","shell.execute_reply":"2023-06-10T11:46:20.707549Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nrf_model = RandomForestClassifier(criterion='entropy', random_state=1,max_features='auto', max_depth=10 ,n_estimators=100                          )\n# fit your model 'max_features': 'sqrt', 'n_estimators': 300\nrf_model.fit(train_X, train_y)\n\n# Calculate the mean absolute error of your Random Forest model on the validation data\nrf_val_predictions = rf_model.predict(val_X)\nrf_val_mae = mean_absolute_error(rf_val_predictions, val_y)\nprint(\"Validation MAE for Random Forest Model: \", rf_val_mae)\na = accuracy_score(val_y, rf_val_predictions) \np = precision_score(val_y, rf_val_predictions)\nr = recall_score(val_y, rf_val_predictions)\nprint(f\"a: {a:.3f}\")\nprint(f\"p: {p:.3f}\")\nprint(f\"r: {r:.3f}\")","metadata":{"execution":{"iopub.status.busy":"2023-06-10T12:21:06.692523Z","iopub.execute_input":"2023-06-10T12:21:06.692885Z","iopub.status.idle":"2023-06-10T12:21:08.233185Z","shell.execute_reply.started":"2023-06-10T12:21:06.692858Z","shell.execute_reply":"2023-06-10T12:21:08.232127Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Get feature importances\nimportances = rf_model.feature_importances_\n\n# Get feature names\nfeature_names = train_X.columns\n\n# Sort feature importances in descending order\nindices = np.argsort(importances)[::-1]\n\n# Print the feature ranking\nprint(\"Feature ranking:\")\nfor f in range(train_X.shape[1]):\n    print(\"%d. feature %d (%f): %s\" % (f + 1, indices[f], importances[indices[f]], feature_names[indices[f]]))\n\n# Plot the feature importances\nplt.figure()\nplt.title(\"Feature importances\")\nplt.bar(range(train_X.shape[1]), importances[indices], color=\"r\", align=\"center\")\nplt.xticks(range(train_X.shape[1]), feature_names[indices], rotation=90)\nplt.xlim([-1, train_X.shape[1]])\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-06-10T11:46:22.263457Z","iopub.execute_input":"2023-06-10T11:46:22.263809Z","iopub.status.idle":"2023-06-10T11:46:22.879698Z","shell.execute_reply.started":"2023-06-10T11:46:22.263783Z","shell.execute_reply":"2023-06-10T11:46:22.878895Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_predictions = rf_model.predict(train_X)\ntrain_mae = mean_absolute_error(train_y, train_predictions)\nprint(\"Training MAE for Random Forest Model: \", train_mae)","metadata":{"execution":{"iopub.status.busy":"2023-06-10T11:46:22.881628Z","iopub.execute_input":"2023-06-10T11:46:22.882146Z","iopub.status.idle":"2023-06-10T11:46:23.176999Z","shell.execute_reply.started":"2023-06-10T11:46:22.882108Z","shell.execute_reply":"2023-06-10T11:46:23.175978Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import learning_curve\nimport matplotlib.pyplot as plt\ntrain_sizes, train_scores, test_scores = learning_curve(rf_model, train_X, train_y, cv=5, scoring='accuracy', n_jobs=-1)\ntrain_mean = np.mean(train_scores, axis=1)\ntrain_std = np.std(train_scores, axis=1)\ntest_mean = np.mean(test_scores, axis=1)\ntest_std = np.std(test_scores, axis=1)\n\nplt.plot(train_sizes, train_mean, 'o-', color='r', label='Training score')\nplt.plot(train_sizes, test_mean, 'o-', color='g', label='Validation score')\nplt.fill_between(train_sizes, train_mean - train_std, train_mean + train_std, alpha=0.1, color='r')\nplt.fill_between(train_sizes, test_mean - test_std, test_mean + test_std, alpha=0.1, color='g')\nplt.xlabel('Training examples')\nplt.ylabel('Score')\nplt.title('Learning Curve')\nplt.legend(loc='best')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-06-10T11:46:32.380596Z","iopub.execute_input":"2023-06-10T11:46:32.381138Z","iopub.status.idle":"2023-06-10T11:46:32.697937Z","shell.execute_reply.started":"2023-06-10T11:46:32.381085Z","shell.execute_reply":"2023-06-10T11:46:32.696804Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\n\ndtree = DecisionTreeClassifier(criterion='gini', random_state=21, max_depth=10,min_samples_leaf= 2, min_samples_split= 5)\n\ndtree.fit(train_X, train_y)\ntree_pred = dtree.predict(val_X)\n\nprint(\"Decision Tree accuracy: \", accuracy_score(val_y, tree_pred))\np = precision_score(val_y, tree_pred)\nr = recall_score(val_y, tree_pred) \nprint(f\"p: {p:.3f}\")\nprint(f\"r: {r:.3f}\")","metadata":{"execution":{"iopub.status.busy":"2023-06-10T11:46:32.699059Z","iopub.execute_input":"2023-06-10T11:46:32.699351Z","iopub.status.idle":"2023-06-10T11:46:32.705721Z","shell.execute_reply.started":"2023-06-10T11:46:32.699325Z","shell.execute_reply":"2023-06-10T11:46:32.704767Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import cross_val_score \n# rf = DecisionTreeClassifier(random_state=21,max_depth=10)\nrf = RandomForestClassifier(random_state=1,max_depth=10)\n\n# # Define the parameter for DT\n# params = {\n#     'max_depth': [None, 5, 10],\n#     'min_samples_split': [2, 5, 10],\n#     'min_samples_leaf': [1, 2, 4],\n#     'criterion': ['gini', 'entropy']\n# }\n\n# for RF\nparams = {\n    'n_estimators': [100, 200, 300],\n    'max_features': ['auto', 'sqrt', 'log2'],\n    'criterion' :['gini', 'entropy']\n}\n\nfrom sklearn.model_selection import GridSearchCV\n\ngrid_search = GridSearchCV(rf, param_grid=params, cv=5)\ngrid_search.fit(train_X, train_y)\n\nbest_params = grid_search.best_params_ \nbest_score = grid_search.best_score_\n\nprint(best_params)\nprint(best_score)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# importances = rf_model.feature_importances_\n# print(\"Feature Importances: \\n\", dict(zip(features, importances)))","metadata":{"execution":{"iopub.status.busy":"2023-06-10T11:50:01.872865Z","iopub.execute_input":"2023-06-10T11:50:01.873193Z","iopub.status.idle":"2023-06-10T11:50:01.877624Z","shell.execute_reply.started":"2023-06-10T11:50:01.873164Z","shell.execute_reply":"2023-06-10T11:50:01.876526Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"a=xx","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from mlxtend.preprocessing import TransactionEncoder\nfrom mlxtend.frequent_patterns import fpgrowth\n\nfrom mlxtend.frequent_patterns import association_rules\ndd=a\ndf_cat = dd[a.columns]\n\n\n\n# Convert the dataframe to a list of lists\nrecords = df_cat.values.tolist()\n \n# Initialize a TransactionEncoder\nte = TransactionEncoder() \n\n# Transform the dataset\nte_data = te.fit_transform(records)\ndf_transformed = pd.DataFrame(te_data, columns=te.columns_)\n\n# Apply FP-growth algorithm\nfrequent_itemsets = fpgrowth(df_transformed, min_support=0.5, use_colnames=True)\n\n# Extract association rules\nrules = association_rules(frequent_itemsets, metric='confidence', min_threshold=0.5, support_only=False, \n                         )\n\n# Print frequent itemsets and rules\nprint(frequent_itemsets)\nprint(rules.head(10))","metadata":{"execution":{"iopub.status.busy":"2023-06-10T11:50:01.878594Z","iopub.execute_input":"2023-06-10T11:50:01.878916Z","iopub.status.idle":"2023-06-10T11:50:01.916507Z","shell.execute_reply.started":"2023-06-10T11:50:01.878882Z","shell.execute_reply":"2023-06-10T11:50:01.915043Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"opp_transformed","metadata":{"execution":{"iopub.status.busy":"2023-06-10T11:50:01.917567Z","iopub.status.idle":"2023-06-10T11:50:01.917968Z","shell.execute_reply.started":"2023-06-10T11:50:01.917785Z","shell.execute_reply":"2023-06-10T11:50:01.917803Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#print(adult_income.dtypes)\ncat_cols = adult_income.select_dtypes(['object', 'category']).columns.tolist()\nprint(cat_cols)","metadata":{"execution":{"iopub.status.busy":"2023-06-10T11:50:01.919562Z","iopub.status.idle":"2023-06-10T11:50:01.920479Z","shell.execute_reply.started":"2023-06-10T11:50:01.92027Z","shell.execute_reply":"2023-06-10T11:50:01.92029Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2023-06-10T11:50:01.921154Z","iopub.status.idle":"2023-06-10T11:50:01.921518Z","shell.execute_reply.started":"2023-06-10T11:50:01.921339Z","shell.execute_reply":"2023-06-10T11:50:01.921354Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### import pandas as pd\nfrom mlxtend.preprocessing import TransactionEncoder\nfrom mlxtend.frequent_patterns import apriori\nfrom mlxtend.frequent_patterns import association_rules\ndd=a\ndf_cat = dd[a.columns]\n\n\n\n# Convert the dataframe to a list of lists\nrecords = df_cat.values.tolist()\n \n# Initialize a TransactionEncoder\nte = TransactionEncoder() \n\n# Transform the dataset\nte_data = te.fit_transform(records)\ndf_transformed = pd.DataFrame(te_data, columns=te.columns_) \n \n\n# Apply Apriori algorithm\nfrequent_itemsets = apriori(df_transformed, min_support=0.7, use_colnames=True)\n\n# Extract association rules\nrules = association_rules(frequent_itemsets, metric='confidence', min_threshold=0.9)\nrules = rules.sort_values(by=['lift'], ascending=False)\n# Print frequent itemsets and rules\nprint(frequent_itemsets)\nprint(rules)\nprint(\"hi\")\n\n# Print the names of the columns with their index position\nfor col in dd.columns:\n    print(col)","metadata":{"execution":{"iopub.status.busy":"2023-06-10T11:50:01.922431Z","iopub.status.idle":"2023-06-10T11:50:01.922765Z","shell.execute_reply.started":"2023-06-10T11:50:01.9226Z","shell.execute_reply":"2023-06-10T11:50:01.922615Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rules.to_csv('rules.csv', index=False)\nfrequent_itemsets.to_csv('freq.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2023-06-10T11:50:01.924108Z","iopub.status.idle":"2023-06-10T11:50:01.924482Z","shell.execute_reply.started":"2023-06-10T11:50:01.924292Z","shell.execute_reply":"2023-06-10T11:50:01.924307Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ru=pd.read_csv('/kaggle/working/rules.csv')\nfr=pd.read_csv('/kaggle/working/freq.csv')\n","metadata":{"execution":{"iopub.status.busy":"2023-06-10T11:50:01.926209Z","iopub.status.idle":"2023-06-10T11:50:01.926578Z","shell.execute_reply.started":"2023-06-10T11:50:01.926404Z","shell.execute_reply":"2023-06-10T11:50:01.92642Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2023-06-10T11:50:01.927617Z","iopub.status.idle":"2023-06-10T11:50:01.927959Z","shell.execute_reply.started":"2023-06-10T11:50:01.927793Z","shell.execute_reply":"2023-06-10T11:50:01.927809Z"},"trusted":true},"execution_count":null,"outputs":[]}]}